{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env MPICH_GPU_SUPPORT_ENABLED=0\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "from astropy.table import Table\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "from numcosmo_py import nc\n",
    "from numcosmo_py import ncm\n",
    "\n",
    "__name__ = \"NcContext\"\n",
    "\n",
    "ncm.cfg_init()\n",
    "ncm.cfg_set_log_handler(lambda msg: sys.stdout.write(msg) and sys.stdout.flush())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cluster catalog and bin definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_catalog = Table.read(\"hamana_clusters.fits\")\n",
    "pz_bins = Table.read(\"pz/s16a_pz_pdf_bins.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `data_cluster_wl` and `likelihood` objects (PDF)\n",
    "\n",
    "Here we create the NumCosmo objects necessary for mass fitting using the full photo-z pdf. These are then serialized into experiment files which can either be loaded by and used by custom python scripts or by the numcosmo CLI app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in tqdm(cluster_catalog):\n",
    "    # Define Cosmology using Planck 2018 parameters (TT, TE, EE+lowE)\n",
    "    cosmo = nc.HICosmoDEXcdm()\n",
    "\n",
    "    cosmo.params_set_default_ftype()\n",
    "    cosmo.omega_x2omega_k()\n",
    "    cosmo[\"H0\"] = 67.27\n",
    "    cosmo[\"Omegab\"] = 0.0494\n",
    "    cosmo[\"Omegac\"] = 0.3166 - 0.0494\n",
    "    cosmo[\"w\"] = -1.0\n",
    "    cosmo[\"Omegak\"] = 0.00\n",
    "\n",
    "    prim = nc.HIPrimPowerLaw.new()\n",
    "    prim[\"n_SA\"] = 0.9649\n",
    "\n",
    "    reion = nc.HIReionCamb.new()\n",
    "\n",
    "    cosmo.param_set_desc(\"H0\", {\"fit\": False})\n",
    "    cosmo.param_set_desc(\"Omegac\", {\"fit\": False})\n",
    "    cosmo.param_set_desc(\"Omegab\", {\"fit\": False})\n",
    "    cosmo.param_set_desc(\"w\", {\"fit\": False})\n",
    "    cosmo.param_set_desc(\"Omegak\", {\"fit\": False})\n",
    "    prim.param_set_desc(\"ln10e10ASA\", {\"fit\": False})\n",
    "    prim.param_set_desc(\"n_SA\", {\"fit\": False})\n",
    "    reion.param_set_desc(\"z_re\", {\"fit\": False})\n",
    "\n",
    "    cosmo.add_submodel(prim)\n",
    "    cosmo.add_submodel(reion)\n",
    "\n",
    "    # Define Halo and WL Models\n",
    "    dist = nc.Distance.new(6.0)\n",
    "    halo_mass_summary = nc.HaloCMParam.new(nc.HaloMassSummaryMassDef.CRITICAL, 200.0)\n",
    "    density_profile = nc.HaloDensityProfileNFW.new(halo_mass_summary)\n",
    "    surface_mass_density = nc.WLSurfaceMassDensity.new(dist)\n",
    "    halo_position = nc.HaloPosition.new(dist)\n",
    "\n",
    "    surface_mass_density.prepare(cosmo)\n",
    "    halo_position.prepare(cosmo)\n",
    "\n",
    "    # Set log10MDelta, cDelta, ra, dec as free parameters\n",
    "    halo_mass_summary.param_set_desc(\"log10MDelta\", {\"fit\": True})\n",
    "    halo_mass_summary.param_set_desc(\"cDelta\", {\"fit\": True})\n",
    "    halo_position.param_set_desc(\"ra\", {\"fit\": True})\n",
    "    halo_position.param_set_desc(\"dec\", {\"fit\": True})\n",
    "\n",
    "    ra = cluster[\"wl_ra\"]\n",
    "    dec = cluster[\"wl_dec\"]\n",
    "    z = cluster[\"z\"]\n",
    "    log10mass = cluster[\"log10M\"]\n",
    "    c = cluster[\"c_2020\"]\n",
    "\n",
    "    halo_position[\"ra\"] = ra\n",
    "    halo_position[\"dec\"] = dec\n",
    "    halo_position[\"z\"] = z\n",
    "\n",
    "    if not isinstance(c, np.float64):\n",
    "        c = 4.0\n",
    "\n",
    "    halo_mass_summary[\"log10MDelta\"] = log10mass\n",
    "    halo_mass_summary[\"cDelta\"] = c\n",
    "\n",
    "    # Use minimum and maximum radius from Hamana et al. 2020\n",
    "    min_radius = 0.3 / cosmo.h()\n",
    "    max_radius = 3.0 / cosmo.h()\n",
    "    # Set boundaries for cluster ra and dec\n",
    "    max_cl_radius = min_radius\n",
    "\n",
    "    # Delta RA necesary to reach max_radius\n",
    "    half_box_side = abs(\n",
    "        fsolve(\n",
    "            lambda sep: halo_position.projected_radius_from_ra_dec(cosmo, ra + sep, dec)\n",
    "            - max_radius,\n",
    "            0.6,\n",
    "        )[0]\n",
    "    )\n",
    "\n",
    "    # Delta RA necesary to reach max_cl_radius\n",
    "    half_box_side_cl = abs(\n",
    "        fsolve(\n",
    "            lambda sep: halo_position.projected_radius_from_ra_dec(cosmo, ra + sep, dec)\n",
    "            - max_cl_radius,\n",
    "            0.6,\n",
    "        )[0]\n",
    "    )\n",
    "\n",
    "    halo_position.param_set_desc(\n",
    "        \"ra\",\n",
    "        {\n",
    "            \"lower-bound\": float(ra - half_box_side_cl),\n",
    "            \"upper-bound\": float(ra + half_box_side_cl),\n",
    "        },\n",
    "    )\n",
    "    # Set dec boundaries taking into account cos(dec) factor\n",
    "    halo_position.param_set_desc(\n",
    "        \"dec\",\n",
    "        {\n",
    "            \"lower-bound\": float(dec - half_box_side_cl * np.cos(np.radians(dec))),\n",
    "            \"upper-bound\": float(dec + half_box_side_cl * np.cos(np.radians(dec))),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Set log10MDelta boundaries\n",
    "    halo_mass_summary.param_set_desc(\n",
    "        \"log10MDelta\",\n",
    "        {\n",
    "            \"lower-bound\": 10.0,\n",
    "            \"upper-bound\": 17.0,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Set cDelta boundaries\n",
    "    halo_mass_summary.param_set_desc(\n",
    "        \"cDelta\",\n",
    "        {\n",
    "            \"lower-bound\": 0.01,\n",
    "            \"upper-bound\": 30.0,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    ra_min = ra - half_box_side\n",
    "    ra_max = ra + half_box_side\n",
    "    dec_min = dec - half_box_side * np.cos(np.radians(dec))\n",
    "    dec_max = dec + half_box_side * np.cos(np.radians(dec))\n",
    "\n",
    "    # Define galaxy distribution models: flat position, p(z) obs, Gaussian shape with\n",
    "    # HSC like bias parametrization and trace ellipticity conventio\n",
    "    galaxy_position = nc.GalaxySDPositionFlat.new(ra_min, ra_max, dec_min, dec_max)\n",
    "    galaxy_redshift_obs = nc.GalaxySDObsRedshiftPz.new()\n",
    "    galaxy_shape = nc.GalaxySDShapeGaussHSC.new(nc.GalaxyWLObsEllipConv.TRACE)\n",
    "\n",
    "    z_data = nc.GalaxySDObsRedshiftData.new(galaxy_redshift_obs)\n",
    "    p_data = nc.GalaxySDPositionData.new(galaxy_position, z_data)\n",
    "    s_data = nc.GalaxySDShapeData.new(galaxy_shape, p_data)\n",
    "\n",
    "    shear_catalog = Table.read(\n",
    "        f\"clusters/{cluster['wl_name']}/{cluster['wl_name']}_shear_catalog.fits\"\n",
    "    )\n",
    "\n",
    "    cut_shear_catalog_dict = {\n",
    "        \"ra\": [],\n",
    "        \"dec\": [],\n",
    "        \"epsilon_obs_1\": [],\n",
    "        \"epsilon_obs_2\": [],\n",
    "        \"std_shape\": [],\n",
    "        \"std_noise\": [],\n",
    "        \"m\": [],\n",
    "        \"c1\": [],\n",
    "        \"c2\": [],\n",
    "    }\n",
    "    cut_shear_catalog_dict[\"pz\"] = []\n",
    "\n",
    "    for i in range(len(shear_catalog)):\n",
    "        radius = halo_position.projected_radius_from_ra_dec(\n",
    "            cosmo, shear_catalog[\"ira\"][i], shear_catalog[\"idec\"][i]\n",
    "        )\n",
    "\n",
    "        # Apply radial cuts from Hamana et al. 2020\n",
    "        if radius > max_radius or radius < min_radius:\n",
    "            continue\n",
    "\n",
    "        # Minimize size of P(z) spline by removing leading and trailing zeros\n",
    "        lower_index = 0\n",
    "        upper_index = len(shear_catalog[\"P(z)\"][i]) - 1\n",
    "\n",
    "        for j in range(len(shear_catalog[\"P(z)\"][i])):\n",
    "            if shear_catalog[\"P(z)\"][i][j] > 0.0:\n",
    "                lower_index = j\n",
    "                break\n",
    "\n",
    "        for j in range(len(shear_catalog[\"P(z)\"][i]) - 1, -1, -1):\n",
    "            if shear_catalog[\"P(z)\"][i][j] > 0.0:\n",
    "                upper_index = j\n",
    "                break\n",
    "\n",
    "        if upper_index - lower_index + 1 < 6:\n",
    "            continue\n",
    "\n",
    "        xv = ncm.Vector.new(upper_index - lower_index + 1)\n",
    "        yv = ncm.Vector.new(upper_index - lower_index + 1)\n",
    "\n",
    "        for j in range(0, upper_index - lower_index + 1):\n",
    "            xv.set(j, np.array(pz_bins[\"BINS\"])[j + lower_index])\n",
    "            yv.set(j, shear_catalog[\"P(z)\"][i][j + lower_index])\n",
    "\n",
    "        pz_spline = ncm.SplineCubicNotaknot.new_full(xv, yv, True)\n",
    "\n",
    "        pz_spline.prepare()\n",
    "\n",
    "        # Normalize P(z)\n",
    "        norm = pz_spline.eval_integ(xv.get(0), xv.get(xv.len() - 1))\n",
    "\n",
    "        for j in range(0, yv.len()):\n",
    "            yv.set(j, yv.get(j) / norm)\n",
    "\n",
    "        pz_spline.prepare()\n",
    "\n",
    "        # P-CUT FROM UMETSU 2020 AND MEDEZINSKI 2018B\n",
    "        p_cut = 0.98\n",
    "        delta_z = 0.2\n",
    "        z_min = halo_position[\"z\"] + delta_z\n",
    "        z_max = 2.5\n",
    "\n",
    "        if z_min >= xv.get(xv.len() - 1):\n",
    "            continue\n",
    "\n",
    "        # Use photo-z MC estimate to apply upper redshift cut\n",
    "        if shear_catalog[\"photoz_mc\"][i] > z_max:\n",
    "            continue\n",
    "\n",
    "        if pz_spline.eval_integ(max(xv.get(0), z_min), xv.get(xv.len() - 1)) < p_cut:\n",
    "            continue\n",
    "\n",
    "        cut_shear_catalog_dict[\"pz\"].append(pz_spline)\n",
    "        cut_shear_catalog_dict[\"ra\"].append(shear_catalog[\"ira\"][i])\n",
    "        cut_shear_catalog_dict[\"dec\"].append(shear_catalog[\"idec\"][i])\n",
    "        cut_shear_catalog_dict[\"epsilon_obs_1\"].append(\n",
    "            shear_catalog[\"ishape_hsm_regauss_e1\"][i]\n",
    "        )\n",
    "        cut_shear_catalog_dict[\"epsilon_obs_2\"].append(\n",
    "            shear_catalog[\"ishape_hsm_regauss_e2\"][i]\n",
    "        )\n",
    "        cut_shear_catalog_dict[\"std_shape\"].append(\n",
    "            shear_catalog[\"ishape_hsm_regauss_derived_rms_e\"][i]\n",
    "        )\n",
    "        cut_shear_catalog_dict[\"std_noise\"].append(\n",
    "            shear_catalog[\"ishape_hsm_regauss_derived_sigma_e\"][i]\n",
    "        )\n",
    "        cut_shear_catalog_dict[\"m\"].append(\n",
    "            shear_catalog[\"ishape_hsm_regauss_derived_shear_bias_m\"][i]\n",
    "        )\n",
    "        cut_shear_catalog_dict[\"c1\"].append(\n",
    "            shear_catalog[\"ishape_hsm_regauss_derived_shear_bias_c1\"][i]\n",
    "        )\n",
    "        cut_shear_catalog_dict[\"c2\"].append(\n",
    "            shear_catalog[\"ishape_hsm_regauss_derived_shear_bias_c2\"][i]\n",
    "        )\n",
    "        cut_shear_catalog_dict[\"z\"].append(shear_catalog[\"photoz_mc\"][i])\n",
    "\n",
    "    print(\n",
    "        f\"Cluster: {cluster['wl_name']}, Number of galaxies: {len(cut_shear_catalog_dict['ra'])}\"\n",
    "    )\n",
    "\n",
    "    # Create observables object\n",
    "    # Note that we are using TRACE ellipticity convention and\n",
    "    # celestial coordinates\n",
    "    wl_obs = nc.GalaxyWLObs.new(\n",
    "        nc.GalaxyWLObsEllipConv.TRACE,\n",
    "        nc.GalaxyWLObsCoord.CELESTIAL,\n",
    "        len(cut_shear_catalog_dict[\"ra\"]),\n",
    "        s_data.required_columns(),\n",
    "    )\n",
    "\n",
    "    for i in range(len(cut_shear_catalog_dict[\"ra\"])):\n",
    "        for key, value in cut_shear_catalog_dict.items():\n",
    "            if key == \"pz\":\n",
    "                wl_obs.set_pz(i, cut_shear_catalog_dict[\"pz\"][i])\n",
    "            else:\n",
    "                wl_obs.set(key, i, value[i])\n",
    "\n",
    "    # Create DataClusterWL object (we do not set radial cuts on the likelihood)\n",
    "    data_cluster = nc.DataClusterWL.new()\n",
    "    data_cluster.set_obs(wl_obs)\n",
    "    data_cluster.set_init(True)\n",
    "\n",
    "    mset = ncm.MSet.new_array(\n",
    "        [\n",
    "            cosmo,\n",
    "            density_profile,\n",
    "            surface_mass_density,\n",
    "            halo_position,\n",
    "            galaxy_position,\n",
    "            galaxy_redshift_obs,\n",
    "            galaxy_shape,\n",
    "        ]\n",
    "    )\n",
    "    dataset = ncm.Dataset.new_array([data_cluster])\n",
    "    likelihood = ncm.Likelihood.new(dataset)\n",
    "\n",
    "    mset.prepare_fparam_map()\n",
    "\n",
    "    experiment = ncm.ObjDictStr()\n",
    "\n",
    "    experiment.set(\"likelihood\", likelihood)\n",
    "    experiment.set(\"model-set\", mset)\n",
    "\n",
    "    ser = ncm.Serialize.new(ncm.SerializeOpt.CLEAN_DUP)\n",
    "\n",
    "    ser.to_binfile(\n",
    "        dataset,\n",
    "        f\"clusters/{cluster['wl_name']}/{cluster['wl_name']}_experiment_pdf.dataset.gvar\",\n",
    "    )\n",
    "    ser.dict_str_to_yaml_file(\n",
    "        experiment,\n",
    "        f\"clusters/{cluster['wl_name']}/{cluster['wl_name']}_experiment_pdf.yaml\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
