{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from numcosmo_py import nc\n",
    "from numcosmo_py import ncm\n",
    "\n",
    "__name__ = \"NcContext\"\n",
    "\n",
    "ncm.cfg_init()\n",
    "ncm.cfg_set_log_handler(lambda msg: sys.stdout.write(msg) and sys.stdout.flush())\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.table import Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cluster catalog\n",
    "\n",
    "Here we choose a specific cluster to fit. You can choose which cluster by changing `cluster_number`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_catalog = Table.read(\"hamana_clusters.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_number = 0\n",
    "cluster = cluster_catalog[cluster_number]\n",
    "print(cluster[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running numcosmo CLI app\n",
    "\n",
    "Below we show a couple of examples on how to run the fit using the numcosmo CLI app. These have to be run on your terminal and won't work on this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# This will calculate the best fit for the experiment\n",
    "numcosmo run fit clusters/HWL16a-002_experiment.yaml -p\n",
    "\n",
    "# This will calculate the Fisher matrix for the experiment\n",
    "numcosmo run fisher clusters/HWL16a-002_experiment.yaml -p\n",
    "\n",
    "# This will run the MCMC analysis using the APES sampler with 200 walkers and 500 samples and 12 threads parallelization\n",
    "numcosmo run mcmc apes clusters/HWL16a-002_experiment.yaml -p --nwalkers 200 --nsamples 500 --parallel threads --nthreads 12\n",
    "\n",
    "# This will run the MCMC analysis using the APES sampler with 200 walkers and 500 samples and MPI parallelization\n",
    "numcosmo run mcmc apes clusters/HWL16a-002_experiment.yaml -p --nwalkers 200 --nsamples 500 --parallel mpi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load experiment (Gauss)\n",
    "\n",
    "We start by loading the serialized experiment for the chosen clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = ncm.Serialize.new(ncm.SerializeOpt.CLEAN_DUP)\n",
    "\n",
    "experiment_path = f\"clusters/{cluster['name']}/{cluster['name']}_experiment.yaml\"\n",
    "dataset_path = f\"clusters/{cluster['name']}/{cluster['name']}_experiment.dataset.gvar\"\n",
    "\n",
    "dataset = ser.from_binfile(dataset_path)\n",
    "experiment_objects = ser.dict_str_from_yaml_file(experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = dataset.get_data(0)\n",
    "\n",
    "likelihood = experiment_objects.get(\"likelihood\")\n",
    "mset = experiment_objects.get(\"model-set\")\n",
    "\n",
    "mset.prepare_fparam_map()\n",
    "\n",
    "galaxy_redshift = mset.peek_by_name(\"NcGalaxySDObsRedshift\")\n",
    "galaxy_position = mset.peek_by_name(\"NcGalaxySDPosition\")\n",
    "galaxy_shape = mset.peek_by_name(\"NcGalaxySDShape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a `pandas` `DataFrame` from our `wl_obs` object..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_obs = cluster_data.peek_obs()\n",
    "\n",
    "wl_obs_dict = {col: [] for col in wl_obs.peek_columns()}\n",
    "\n",
    "for i in range(wl_obs.len()):\n",
    "    for col in wl_obs_dict.keys():\n",
    "        wl_obs_dict[col].append(wl_obs.get(col, i))\n",
    "\n",
    "wl_obs_df = pd.DataFrame(wl_obs_dict)\n",
    "\n",
    "wl_obs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and plot histograms for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_obs_df.hist(\n",
    "    column=[\n",
    "        \"epsilon_obs_1\",\n",
    "        \"epsilon_obs_2\",\n",
    "        \"sigma_int\",\n",
    "        \"sigma_obs\",\n",
    "        \"ra\",\n",
    "        \"dec\",\n",
    "        \"zp\",\n",
    "    ],\n",
    "    bins=50,\n",
    "    figsize=(14, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a fit object and calculate a best fit and fisher matrix. The fisher matrix specifically can take some time to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = ncm.Fit.factory(\n",
    "    ncm.FitType.NLOPT,\n",
    "    \"ln-neldermead\",\n",
    "    likelihood,\n",
    "    mset,\n",
    "    ncm.FitGradType.NUMDIFF_FORWARD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.run(ncm.FitRunMsgs.SIMPLE)\n",
    "print(\n",
    "    f\"Original -> ra: {cluster['ra']}, dec: {cluster['dec']}, log10M: {np.log10(cluster['m200_wmap'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.obs_fisher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.log_info()\n",
    "fit.log_covar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we run a MCMC analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncm.func_eval_set_max_threads(12)\n",
    "ncm.func_eval_log_pool_stats()\n",
    "\n",
    "init_sampler = ncm.MSetTransKernGauss.new(0)\n",
    "init_sampler.set_mset(mset)\n",
    "init_sampler.set_prior_from_mset()\n",
    "init_sampler.set_cov_from_rescale(1.0e-1)\n",
    "\n",
    "nwalkers = 200\n",
    "stretch = ncm.FitESMCMCWalkerAPES.new(nwalkers, mset.fparams_len())\n",
    "esmcmc = ncm.FitESMCMC.new(fit, nwalkers, init_sampler, stretch, ncm.FitRunMsgs.SIMPLE)\n",
    "\n",
    "esmcmc.set_auto_trim_div(100)\n",
    "esmcmc.set_max_runs_time(2.0 * 60.0)\n",
    "esmcmc.set_data_file(\n",
    "    f\"clusters/{cluster['name']}/{cluster['name']}_experiment.python.fits\"\n",
    ")\n",
    "esmcmc.set_nthreads(12)\n",
    "esmcmc.start_run()\n",
    "esmcmc.run(100000 / nwalkers)\n",
    "esmcmc.end_run()\n",
    "\n",
    "mcat = esmcmc.peek_catalog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load experiment (PDF)\n",
    "\n",
    "We start by loading the serialized experiment for the chosen clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = ncm.Serialize.new(ncm.SerializeOpt.CLEAN_DUP)\n",
    "\n",
    "experiment_path = f\"clusters/{cluster['name']}/{cluster['name']}_experiment_pdf.yaml\"\n",
    "dataset_path = (\n",
    "    f\"clusters/{cluster['name']}/{cluster['name']}_experiment_pdf.dataset.gvar\"\n",
    ")\n",
    "\n",
    "dataset = ser.from_binfile(dataset_path)\n",
    "experiment_objects = ser.dict_str_from_yaml_file(experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = dataset.get_data(0)\n",
    "\n",
    "likelihood = experiment_objects.get(\"likelihood\")\n",
    "mset = experiment_objects.get(\"model-set\")\n",
    "\n",
    "mset.prepare_fparam_map()\n",
    "\n",
    "galaxy_redshift = mset.peek_by_name(\"NcGalaxySDObsRedshift\")\n",
    "galaxy_position = mset.peek_by_name(\"NcGalaxySDPosition\")\n",
    "galaxy_shape = mset.peek_by_name(\"NcGalaxySDShape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a `pandas` `DataFrame` from our `wl_obs` object (notice we leave out the P(z) data)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_obs = cluster_data.peek_obs()\n",
    "\n",
    "wl_obs_dict = {col: [] for col in wl_obs.peek_columns()}\n",
    "\n",
    "for i in range(wl_obs.len()):\n",
    "    for col in wl_obs_dict.keys():\n",
    "        wl_obs_dict[col].append(wl_obs.get(col, i))\n",
    "\n",
    "wl_obs_df = pd.DataFrame(wl_obs_dict)\n",
    "\n",
    "wl_obs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and plot histograms for our data (here, `z` is `photo_z_best` and is not used on the analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_obs_df.hist(\n",
    "    column=[\n",
    "        \"epsilon_obs_1\",\n",
    "        \"epsilon_obs_2\",\n",
    "        \"sigma_int\",\n",
    "        \"sigma_obs\",\n",
    "        \"ra\",\n",
    "        \"dec\",\n",
    "        \"z\",\n",
    "    ],\n",
    "    bins=50,\n",
    "    figsize=(14, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a fit object and calculate a best fit and fisher matrix. The fisher matrix specifically can take some time to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = ncm.Fit.factory(\n",
    "    ncm.FitType.NLOPT,\n",
    "    \"ln-neldermead\",\n",
    "    likelihood,\n",
    "    mset,\n",
    "    ncm.FitGradType.NUMDIFF_FORWARD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.run(ncm.FitRunMsgs.SIMPLE)\n",
    "print(\n",
    "    f\"Original -> ra: {cluster['ra']}, dec: {cluster['dec']}, log10M: {np.log10(cluster['m200_wmap'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.obs_fisher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.log_info()\n",
    "fit.log_covar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we run a MCMC analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncm.func_eval_set_max_threads(12)\n",
    "ncm.func_eval_log_pool_stats()\n",
    "\n",
    "init_sampler = ncm.MSetTransKernGauss.new(0)\n",
    "init_sampler.set_mset(mset)\n",
    "init_sampler.set_prior_from_mset()\n",
    "init_sampler.set_cov_from_rescale(1.0e-1)\n",
    "\n",
    "nwalkers = 200\n",
    "stretch = ncm.FitESMCMCWalkerAPES.new(nwalkers, mset.fparams_len())\n",
    "esmcmc = ncm.FitESMCMC.new(fit, nwalkers, init_sampler, stretch, ncm.FitRunMsgs.SIMPLE)\n",
    "\n",
    "esmcmc.set_auto_trim_div(100)\n",
    "esmcmc.set_max_runs_time(2.0 * 60.0)\n",
    "esmcmc.set_data_file(\n",
    "    f\"clusters/{cluster['name']}/{cluster['name']}_experiment.python.fits\"\n",
    ")\n",
    "esmcmc.set_nthreads(12)\n",
    "esmcmc.start_run()\n",
    "esmcmc.run(100000 / nwalkers)\n",
    "esmcmc.end_run()\n",
    "\n",
    "mcat = esmcmc.peek_catalog()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
